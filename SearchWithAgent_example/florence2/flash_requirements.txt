flash-attn #enable for flash attention, flash attention must have have CUDA 11.7 and above 